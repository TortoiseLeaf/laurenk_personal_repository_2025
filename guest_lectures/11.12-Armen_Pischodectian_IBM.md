Five types of agentic AI

components of agentic AI 

MCP instead of API

AI agents are single purpose digital entities for specific tasks, chatbots

Agentic AI is goal driven system that sets their own strategies and collaborates across workflows
the decider and the doer


Agentic AI adapts iwthout human intervention
Learn from experiences and interaction, make autonomous decisions.

!research the best dog food and order it for me"

different levels of agents:
Instant rule follower, zero memory. door opener, thermostat

Context keeper, keeps an internal state to handle partially observable situations, Roomba

Goal driven tool user, GPS navigation planning a route, meeting scheduler checks calendars proposes times sends invite

decision optimizer balances trade-offs to maximize a score, accuracy vs speed vs diversity
much more bias built in 
self-driving cars trade safety, comfort and time 
cloud auto-scaler balances latency targets with compute costs.

Self-improving autopilot model improves from data feedback. used as personalized study coach adjusts difficulty form quiz feedback
close by connecting learning loops

put it all together. agentic apps combine memory, goal-driver tool use, utility to pick the best option and light learning loop from feedback

like a travel planner, prefs + flight/hotel APIs + budget/comfort score + adapts.
learns preferences.

perception of goal, what it is, why it matters, example a help bot reads a customer chat and extracts the issue


Reasoning, turning input into conclusions, prevents 'knee-jerk' replies. reading the order number, then checks shipping status

Memory, info the system keeps for later. Matters because it keeps context across steps. bot remembers the customers preferred refund method from chat

planning, laying out steps to reach a goal, multi-step tasks (orchestrator, lang-flow, lang-graph, )
example reschedule a meeting, sends invites etc

Action, doing the work like calling an api invoking an mcp, without action everything else is just prep
confirming a late delivery the system issues a replacement. 



Doesn't happen in that order every time.

### Every thought captive. kyle idleman


agentic and gen ai both need to tap into an LLM the reasoning part needs it. 


8n8 prebuilt agents. n8n.io






OpenAI free tier
crewAI
AutoGen
beeai-framework
Langchain LangGraph

granite and llama 3 models.


Langchain is a toolchain for building AI applications. universal port for connections between AI application components. it's a framework

LLamaindex great of rag
Haystack 

LangChain is model agnostic. 
MCP is the protocol to connect agents to tools. LangChain is the framework that can use MCP servers as tools. They're complimentary.

use cases
intake scheduling agent books appointments, pre-writes estimates from photos, checks parts availability, updates customers by SMS during repairs and assembles insurance paperwork. 

automation with thinking basically


Salons
concierge agent matches clients to stylists, manages waitlist and no-show policies, sends reminders, recommends retail add-ons.

tenatn support agent traige maintenance requests with phtoos. book vendors, send reminders, draft lease renewals.





AI security 
llms don't know malicious data
prompt injection risk

the lethatl trifecta is exposure to outside content, access to private data (emails, code, passwords) and 3, abilitiy to ac/communicate with the outside world.

better to limit access?

copiliopt had a trifecta vulnerability they patched

DPD AI chatbot used foul language

LLM is inherently gullible as a system, the combination makes it vulnerable.


Mitigation

Break the trifecta, don't give a single workflow all three

POLP, narrow tools

Treat model outputs as untrusted, sandbox actions

Harden inputs RAG vetted sources
Monitor & fail-safe Log, rate-limit and be ready to disable misbehaving bots quickly like DPD did

Mindset


# LMStudio.ai
# ollama in terminal


core formula from least squares

use jupyter notebook to work the agents and have it containerized. can have it output in different formats like csv or png etc because it can use generative AI

mad. used as a tool 

mistral

different agents in the same one

nutritionist, dietician, recipe  maker, vision analyst detects labels

you can input an image, the vision analyst detects labels to pass on to the nutritionist agent, who then passes on the info to the recipe planner using that data. so it's really high level data processing

so it reverse engineers your meal, that's mad.


take less from the machine rather than give it more
remove something from the trifecta.

RAG is helpful Retrieval-Augmented Generation




Model context protocol

LLM to LAM so from language and planning to Action models

Orchestrators 


What prevents Agentic AI from developing bias if it keeps memory of the previous data to learn on? can the bias be offset by a bigger pool of data used for the reasoning?
localize the focus so it's only working with logic more than too much information

https://youtube.com/playlist?list=PLW1lm2-ok5f1R9UOw9dzO4Yq0FOsoR0SH&si=pzBynlDbh44wfPW7



ADD DAINIS




